{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (3.5.5)\n",
      "Requirement already satisfied: findspark in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (2.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/tatianaflores/Library/Python/3.9/lib/python/site-packages (from pyspark) (0.10.9.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_KW73O2e3dw",
    "outputId": "fa5fd2b3-e2de-491b-ee1c-405317ba7ebc"
   },
   "outputs": [],
   "source": [
    "# Import findspark and initialize.\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "2XbWNf1Te5fM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/26 22:49:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"HomeSales\").getOrCreate()\n",
    "df = spark.read.csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.createOrReplaceTempView(\"home_sales_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOJqxG_RPSwp",
    "outputId": "7857ef9f-5b04-405d-f5aa-e535dfe7870c"
   },
   "outputs": [],
   "source": [
    "# 1. Read the home_sales_revised.csv from the provided AWS S3 bucket location into a PySpark DataFrame.\n",
    "from pyspark import SparkFiles\n",
    "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/26 22:49:40 WARN SparkContext: The path https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv has been added already. Overwriting of added paths is not supported in the current version.\n"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.addFile(\"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>date_built</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f8a53099-ba1c-47d6-9c31-7398aa8f6089</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>2016</td>\n",
       "      <td>936923</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3167</td>\n",
       "      <td>11733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7530a2d8-1ae3-4517-9f4a-befe060c4353</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>2013</td>\n",
       "      <td>379628</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2235</td>\n",
       "      <td>14384</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43de979c-0bf0-4c9f-85ef-96dc27b258d5</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>2014</td>\n",
       "      <td>417866</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2127</td>\n",
       "      <td>10575</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b672c137-b88c-48bf-9f18-d0a4ac62fb8b</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>239895</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1631</td>\n",
       "      <td>11149</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e0726d4d-d595-4074-8283-4139a54d0d63</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2017</td>\n",
       "      <td>424418</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2249</td>\n",
       "      <td>13878</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33282</th>\n",
       "      <td>c9586491-b7c9-41e9-93ae-d8e0a9f792d0</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>2011</td>\n",
       "      <td>422922</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1667</td>\n",
       "      <td>14548</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33283</th>\n",
       "      <td>2ffb54d1-9ac7-4d78-95f3-7ba4cde42d9e</td>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>2014</td>\n",
       "      <td>238605</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1937</td>\n",
       "      <td>8906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33284</th>\n",
       "      <td>6f319eab-b34d-4179-8d68-6260670cad23</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>2013</td>\n",
       "      <td>120781</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1567</td>\n",
       "      <td>11864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33285</th>\n",
       "      <td>629575b0-915e-4173-8b24-be271918ca69</td>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>2015</td>\n",
       "      <td>280919</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2179</td>\n",
       "      <td>14934</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33286</th>\n",
       "      <td>de706716-721a-42fb-b14c-14c65a84593f</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>2011</td>\n",
       "      <td>398322</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2119</td>\n",
       "      <td>12756</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33287 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id        date  date_built   price  \\\n",
       "0      f8a53099-ba1c-47d6-9c31-7398aa8f6089  2022-04-08        2016  936923   \n",
       "1      7530a2d8-1ae3-4517-9f4a-befe060c4353  2021-06-13        2013  379628   \n",
       "2      43de979c-0bf0-4c9f-85ef-96dc27b258d5  2019-04-12        2014  417866   \n",
       "3      b672c137-b88c-48bf-9f18-d0a4ac62fb8b  2019-10-16        2016  239895   \n",
       "4      e0726d4d-d595-4074-8283-4139a54d0d63  2022-01-08        2017  424418   \n",
       "...                                     ...         ...         ...     ...   \n",
       "33282  c9586491-b7c9-41e9-93ae-d8e0a9f792d0  2019-05-20        2011  422922   \n",
       "33283  2ffb54d1-9ac7-4d78-95f3-7ba4cde42d9e  2021-04-13        2014  238605   \n",
       "33284  6f319eab-b34d-4179-8d68-6260670cad23  2021-05-11        2013  120781   \n",
       "33285  629575b0-915e-4173-8b24-be271918ca69  2021-12-21        2015  280919   \n",
       "33286  de706716-721a-42fb-b14c-14c65a84593f  2019-06-20        2011  398322   \n",
       "\n",
       "       bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \n",
       "0             4          3         3167     11733       2           1    76  \n",
       "1             2          2         2235     14384       1           0    23  \n",
       "2             2          2         2127     10575       2           0     0  \n",
       "3             2          2         1631     11149       2           0     0  \n",
       "4             3          2         2249     13878       2           0     4  \n",
       "...         ...        ...          ...       ...     ...         ...   ...  \n",
       "33282         3          3         1667     14548       2           0    44  \n",
       "33283         3          2         1937      8906       1           0    30  \n",
       "33284         4          3         1567     11864       1           0    44  \n",
       "33285         2          2         2179     14934       2           0    29  \n",
       "33286         4          2         2119     12756       2           0     8  \n",
       "\n",
       "[33287 rows x 11 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|                 _c0|       _c1|       _c2|   _c3|     _c4|      _c5|        _c6|     _c7|   _c8|       _c9|_c10|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n",
      "|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n",
      "|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n",
      "|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n",
      "|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n",
      "|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n",
      "|5aa00529-0533-46b...|2019-01-30|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|\n",
      "|131492a1-72e2-4a8...|2020-02-08|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|\n",
      "|8d54a71b-c520-44e...|2019-07-21|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|\n",
      "|e81aacfe-17fe-46b...|2020-06-16|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|\n",
      "|2ed8d509-7372-46d...|2021-08-06|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|\n",
      "|f876d86f-3c9f-42b...|2019-02-27|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|\n",
      "|0a2bd445-8508-4d8...|2021-12-30|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|\n",
      "|941bad30-eb49-4a7...|2020-05-09|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|\n",
      "|dd61eb34-6589-4c0...|2021-07-25|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|\n",
      "|f1e4cef7-d151-439...|2019-02-01|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|\n",
      "|ea620c7b-c2f7-4c6...|2021-05-31|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|\n",
      "|f233cb41-6f33-4b0...|2021-07-18|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|\n",
      "|c797ca12-52cd-4b1...|2019-06-08|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|\n",
      "|0cfe57f3-28c2-472...|2019-10-04|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "home_sales_df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"))\n",
    "home_sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "RoljcJ7WPpnm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/26 22:49:47 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# 2. Create a temporary view of the DataFrame.\n",
    "home_sales_df.createOrReplaceTempView('home_sales')\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName('home_sales').getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id        date  date_built   price  \\\n",
      "0  f8a53099-ba1c-47d6-9c31-7398aa8f6089  2022-04-08        2016  936923   \n",
      "1  7530a2d8-1ae3-4517-9f4a-befe060c4353  2021-06-13        2013  379628   \n",
      "2  43de979c-0bf0-4c9f-85ef-96dc27b258d5  2019-04-12        2014  417866   \n",
      "3  b672c137-b88c-48bf-9f18-d0a4ac62fb8b  2019-10-16        2016  239895   \n",
      "4  e0726d4d-d595-4074-8283-4139a54d0d63  2022-01-08        2017  424418   \n",
      "\n",
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \n",
      "0         4          3         3167     11733       2           1    76  \n",
      "1         2          2         2235     14384       1           0    23  \n",
      "2         2          2         2127     10575       2           0     0  \n",
      "3         2          2         1631     11149       2           0     0  \n",
      "4         3          2         2249     13878       2           0     4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6fkwOeOmqvq",
    "outputId": "bdded620-79c4-488d-c7a5-91c6799c419e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_sold  average_price\n",
      "0       2019      300263.70\n",
      "1       2020      298353.78\n",
      "2       2021      301819.44\n",
      "3       2022      296363.88\n"
     ]
    }
   ],
   "source": [
    "# 3. What is the average price for a four bedroom house sold per year, rounded to two decimal places?\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\")\n",
    "\n",
    "# Convert 'date' column to datetime format and extract year\n",
    "df['year_sold'] = pd.to_datetime(df['date']).dt.year\n",
    "\n",
    "# Filter for 4-bedroom houses\n",
    "four_bed_df = df[df['bedrooms'] == 4]\n",
    "\n",
    "# Group by year and calculate average price, rounded to 2 decimal places\n",
    "avg_price_per_year = (\n",
    "    four_bed_df.groupby('year_sold')['price']\n",
    "    .mean()\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    "    .rename(columns={'price': 'average_price'})\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "print(avg_price_per_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8p_tUS8h8it",
    "outputId": "65806e5f-6262-41c0-ff65-5107464e5c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_built  average_price\n",
      "0        2010      292859.62\n",
      "1        2011      291117.47\n",
      "2        2012      293683.19\n",
      "3        2013      295962.27\n",
      "4        2014      290852.27\n",
      "5        2015      288770.30\n",
      "6        2016      290555.07\n",
      "7        2017      292676.79\n"
     ]
    }
   ],
   "source": [
    "# 4. What is the average price of a home for each year the home was built,\n",
    "# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n",
    "\n",
    "# Filter for homes with 3 bedrooms and 3 bathrooms\n",
    "filtered_df = df[(df['bedrooms'] == 3) & (df['bathrooms'] == 3)]\n",
    "\n",
    "# Group by year the home was built and calculate average price\n",
    "avg_price_per_year_built = (\n",
    "    filtered_df.groupby('date_built')['price']\n",
    "    .mean()\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    "    .rename(columns={'price': 'average_price'})\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "print(avg_price_per_year_built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-Eytz64liDU",
    "outputId": "17119810-56ad-40c3-de5e-c3db57e43bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_built  average_price\n",
      "0        2010      285010.22\n",
      "1        2011      276553.81\n",
      "2        2012      307539.97\n",
      "3        2013      303676.79\n",
      "4        2014      298264.72\n",
      "5        2015      297609.97\n",
      "6        2016      293965.10\n",
      "7        2017      280317.58\n"
     ]
    }
   ],
   "source": [
    "# 5. What is the average price of a home for each year the home was built,\n",
    "# that have 3 bedrooms, 3 bathrooms, with two floors,\n",
    "# and are greater than or equal to 2,000 square feet, rounded to two decimal places?\n",
    "\n",
    "# Filter the DataFrame based on the conditions\n",
    "filtered_df = df[\n",
    "    (df['bedrooms'] == 3) &\n",
    "    (df['bathrooms'] == 3) &\n",
    "    (df['floors'] == 2) &\n",
    "    (df['sqft_living'] >= 2000)\n",
    "]\n",
    "\n",
    "# Group by year the home was built and calculate average price\n",
    "avg_price = (\n",
    "    filtered_df.groupby('date_built')['price']\n",
    "    .mean()\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    "    .rename(columns={'price': 'average_price'})\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "print(avg_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUrfgOX1pCRd",
    "outputId": "17c25774-855e-4290-a4bd-a04902bdc13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     view  average_price\n",
      "100   100     1026669.50\n",
      "99     99     1061201.42\n",
      "98     98     1053739.33\n",
      "97     97     1129040.15\n",
      "96     96     1017815.92\n",
      "95     95     1054325.60\n",
      "94     94     1033536.20\n",
      "93     93     1026006.06\n",
      "92     92      970402.55\n",
      "91     91     1137372.73\n",
      "90     90     1062654.16\n",
      "89     89     1107839.15\n",
      "88     88     1031719.35\n",
      "87     87     1072285.20\n",
      "86     86     1070444.25\n",
      "85     85     1056336.74\n",
      "84     84     1117233.13\n",
      "83     83     1033965.92\n",
      "82     82     1063498.00\n",
      "81     81     1053472.79\n",
      "80     80      991767.38\n",
      "79     79     1009565.08\n",
      "78     78     1080649.37\n",
      "77     77     1076205.56\n",
      "76     76     1058802.78\n",
      "75     75     1114042.94\n",
      "74     74      745077.00\n",
      "73     73      752861.18\n",
      "72     72      780914.67\n",
      "71     71      775651.10\n",
      "70     70      695865.58\n",
      "69     69      750537.94\n",
      "68     68      716785.44\n",
      "67     67      737970.96\n",
      "66     66      712475.00\n",
      "65     65      736679.93\n",
      "64     64      767036.67\n",
      "63     63      711614.55\n",
      "62     62      759150.14\n",
      "61     61      746877.59\n",
      "60     60      754939.65\n",
      "59     59      791453.00\n",
      "58     58      759764.65\n",
      "57     57      734340.50\n",
      "56     56      718176.40\n",
      "55     55      771153.32\n",
      "54     54      798684.82\n",
      "53     53      755214.80\n",
      "52     52      733780.26\n",
      "51     51      788128.21\n",
      "\n",
      "Query runtime: 0.0118 seconds\n",
      "--- 0.02477407455444336 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n",
    "# having an average home price greater than or equal to $350,000? Order by descending view rating.\n",
    "# Although this is a small dataset, determine the run time for this query.\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Group by 'view', calculate average price, filter, round, and sort\n",
    "avg_price_by_view = (\n",
    "    df.groupby('view')['price']\n",
    "    .mean()\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    "    .rename(columns={'price': 'average_price'})\n",
    ")\n",
    "\n",
    "# Filter for average price >= 350,000\n",
    "filtered_result = avg_price_by_view[avg_price_by_view['average_price'] >= 350000]\n",
    "\n",
    "# Sort by view in descending order\n",
    "filtered_result = filtered_result.sort_values(by='view', ascending=False)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "# Display the results\n",
    "print(filtered_result)\n",
    "print(f\"\\nQuery runtime: {runtime:.4f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAhk3ZD2tFy8",
    "outputId": "0a8f132d-40a8-4bd4-b5f2-2847e98427f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/26 22:50:05 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# 7. Cache the the temporary table home_sales.\n",
    "spark.catalog.cacheTable(\"home_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|                 _c0|       _c1|       _c2|   _c3|     _c4|      _c5|        _c6|     _c7|   _c8|       _c9|_c10|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n",
      "|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n",
      "|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n",
      "|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n",
      "|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run a query to trigger the cache\n",
    "spark.sql(\"SELECT * FROM home_sales LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4opVhbvxtL-i",
    "outputId": "38ec8487-795f-4550-b50c-fcc6f2b7c769"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Check if the table is cached.\n",
    "spark.catalog.isCached('home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GnL46lwTSEk",
    "outputId": "09a16c73-194d-4371-95d1-ee64fe83b91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|view|average_price|\n",
      "+----+-------------+\n",
      "| 100|    1026669.5|\n",
      "|  99|   1061201.42|\n",
      "|  98|   1053739.33|\n",
      "|  97|   1129040.15|\n",
      "|  96|   1017815.92|\n",
      "|  95|    1054325.6|\n",
      "|  94|    1033536.2|\n",
      "|  93|   1026006.06|\n",
      "|  92|    970402.55|\n",
      "|  91|   1137372.73|\n",
      "|  90|   1062654.16|\n",
      "|  89|   1107839.15|\n",
      "|  88|   1031719.35|\n",
      "|  87|    1072285.2|\n",
      "|  86|   1070444.25|\n",
      "|  85|   1056336.74|\n",
      "|  84|   1117233.13|\n",
      "|  83|   1033965.93|\n",
      "|  82|    1063498.0|\n",
      "|  81|   1053472.79|\n",
      "+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "⏱ Uncached query runtime: 1.2468 seconds\n",
      "+----+-------------+\n",
      "|view|average_price|\n",
      "+----+-------------+\n",
      "| 100|    1026669.5|\n",
      "|  99|   1061201.42|\n",
      "|  98|   1053739.33|\n",
      "|  97|   1129040.15|\n",
      "|  96|   1017815.92|\n",
      "|  95|    1054325.6|\n",
      "|  94|    1033536.2|\n",
      "|  93|   1026006.06|\n",
      "|  92|    970402.55|\n",
      "|  91|   1137372.73|\n",
      "|  90|   1062654.16|\n",
      "|  89|   1107839.15|\n",
      "|  88|   1031719.35|\n",
      "|  87|    1072285.2|\n",
      "|  86|   1070444.25|\n",
      "|  85|   1056336.74|\n",
      "|  84|   1117233.13|\n",
      "|  83|   1033965.93|\n",
      "|  82|    1063498.0|\n",
      "|  81|   1053472.79|\n",
      "+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "⚡ Cached query runtime: 0.3540 seconds\n"
     ]
    }
   ],
   "source": [
    "# 9. Using the cached data, run the last query above, that calculates\n",
    "# the average price of a home per \"view\" rating, rounded to two decimal places,\n",
    "# having an average home price greater than or equal to $350,000.\n",
    "# Determine the runtime and compare it to the uncached runtime.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, round\n",
    "import time\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"HomeSalesQuery\").getOrCreate()\n",
    "\n",
    "# Load CSV as PySpark DataFrame\n",
    "df = spark.read.csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Register as temp view\n",
    "df.createOrReplaceTempView(\"home_sales\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Uncached Query Runtime\n",
    "# -------------------------------------------\n",
    "start_uncached = time.time()\n",
    "\n",
    "uncached_result = spark.sql(\"\"\"\n",
    "    SELECT view, ROUND(AVG(price), 2) AS average_price\n",
    "    FROM home_sales\n",
    "    GROUP BY view\n",
    "    HAVING average_price >= 350000\n",
    "    ORDER BY view DESC\n",
    "\"\"\")\n",
    "uncached_result.show()\n",
    "\n",
    "end_uncached = time.time()\n",
    "uncached_runtime = end_uncached - start_uncached\n",
    "print(f\"⏱ Uncached query runtime: {uncached_runtime:.4f} seconds\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Cache the view\n",
    "# -------------------------------------------\n",
    "spark.catalog.cacheTable(\"home_sales\")\n",
    "\n",
    "# Run a small query to \"warm up\" the cache\n",
    "spark.sql(\"SELECT * FROM home_sales LIMIT 1\").collect()\n",
    "\n",
    "start_cached = time.time()\n",
    "\n",
    "cached_result = spark.sql(\"\"\"\n",
    "    SELECT view, ROUND(AVG(price), 2) AS average_price\n",
    "    FROM home_sales\n",
    "    GROUP BY view\n",
    "    HAVING average_price >= 350000\n",
    "    ORDER BY view DESC\n",
    "\"\"\")\n",
    "cached_result.show()\n",
    "\n",
    "end_cached = time.time()\n",
    "cached_runtime = end_cached - start_cached\n",
    "print(f\"⚡ Cached query runtime: {cached_runtime:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "Qm12WN9isHBR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"PartitionByDateBuilt\").getOrCreate()\n",
    "\n",
    "# Load the CSV as PySpark DataFrame (if not already loaded)\n",
    "df = spark.read.csv(\"/Users/tatianaflores/Desktop/home_sales_revised.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Write to Parquet, partitioned by 'date_built'\n",
    "df.write.mode(\"overwrite\") \\\n",
    "    .partitionBy(\"date_built\") \\\n",
    "    .parquet(\"/Users/tatianaflores/Desktop/home_sales_partitioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "AZ7BgY61sRqY"
   },
   "outputs": [],
   "source": [
    "# 11. Read the formatted parquet data.\n",
    "parquet_df = spark.read.parquet(\"Users/tatianaflores/Desktop/home_sales_partitioned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "J6MJkHfvVcvh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- bathrooms: integer (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: integer (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- date_built: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "|                  id|      date| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|date_built|\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "|2ed8d509-7372-46d...|2021-08-06|258710|       3|        3|       1918|    9666|     1|         0|  25|      2015|\n",
      "|941bad30-eb49-4a7...|2020-05-09|229896|       3|        3|       2197|    8641|     1|         0|   3|      2015|\n",
      "|c797ca12-52cd-4b1...|2019-06-08|288650|       2|        3|       2100|   10419|     2|         0|   7|      2015|\n",
      "|0cfe57f3-28c2-472...|2019-10-04|308313|       3|        3|       1960|    9453|     2|         0|   2|      2015|\n",
      "|d715f295-2fbf-4e9...|2021-05-17|391574|       3|        2|       1635|    8040|     2|         0|  10|      2015|\n",
      "|a18515a2-86f3-46b...|2022-02-18|419543|       3|        2|       1642|   12826|     2|         0|  24|      2015|\n",
      "|98f6a9ad-8870-474...|2022-05-07|136752|       2|        3|       1701|   10771|     2|         0|   5|      2015|\n",
      "|7ac67498-b6f3-403...|2021-05-12|349318|       4|        3|       2417|   11304|     2|         0|  37|      2015|\n",
      "|c9bfdb1c-2499-4e3...|2021-12-07|268874|       2|        2|       1537|   12177|     1|         0|  10|      2015|\n",
      "|34c31a34-220d-469...|2019-02-06|409011|       3|        3|       2356|   10507|     1|         0|   1|      2015|\n",
      "|be0ccb95-415d-411...|2020-05-15|425154|       4|        3|       2120|   14229|     2|         0|   4|      2015|\n",
      "|e9031a86-1294-444...|2021-10-09|222322|       4|        3|       1928|   10510|     1|         0|  38|      2015|\n",
      "|e6d7c2a7-596e-4ec...|2019-03-15|131201|       4|        3|       1633|   14655|     1|         0|  22|      2015|\n",
      "|6683714b-3df7-454...|2022-02-01|333403|       4|        2|       2059|    9793|     2|         0|   4|      2015|\n",
      "|00fc996f-508c-430...|2021-07-15|373139|       3|        3|       1763|   11363|     1|         0|  39|      2015|\n",
      "|3d5545f8-bd3b-476...|2020-09-19|797862|       4|        6|       3494|   10385|     2|         0|  90|      2015|\n",
      "|ec6d357c-2435-43e...|2019-05-28|401792|       3|        2|       1627|   10765|     1|         0|  50|      2015|\n",
      "|c2be38fb-814a-403...|2020-03-20|352237|       3|        3|       2485|   10954|     2|         0|   6|      2015|\n",
      "|9570de1f-5a74-45b...|2021-11-29|298453|       3|        2|       2222|   10634|     1|         0|   6|      2015|\n",
      "|1baeff4f-fc00-489...|2020-12-17|152775|       3|        2|       1623|   13851|     1|         0|  41|      2015|\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Create a temporary table for the parquet data.\n",
    "parquet_df.printSchema()\n",
    "parquet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_Vhb52rU1Sn",
    "outputId": "a0b8d0c4-55ed-4c6c-bfd8-4c8c5334838e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|view|average_price|\n",
      "+----+-------------+\n",
      "| 100|    1026669.5|\n",
      "|  99|   1061201.42|\n",
      "|  98|   1053739.33|\n",
      "|  97|   1129040.15|\n",
      "|  96|   1017815.92|\n",
      "|  95|    1054325.6|\n",
      "|  94|    1033536.2|\n",
      "|  93|   1026006.06|\n",
      "|  92|    970402.55|\n",
      "|  91|   1137372.73|\n",
      "|  90|   1062654.16|\n",
      "|  89|   1107839.15|\n",
      "|  88|   1031719.35|\n",
      "|  87|    1072285.2|\n",
      "|  86|   1070444.25|\n",
      "|  85|   1056336.74|\n",
      "|  84|   1117233.13|\n",
      "|  83|   1033965.93|\n",
      "|  82|    1063498.0|\n",
      "|  81|   1053472.79|\n",
      "+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "📦 Parquet query runtime: 0.3251 seconds\n",
      "--- 0.3253288269042969 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 13. Using the parquet DataFrame, run the last query above, that calculates\n",
    "# the average price of a home per \"view\" rating, rounded to two decimal places,\n",
    "# having an average home price greater than or equal to $350,000.\n",
    "# Determine the runtime and compare it to the cached runtime.\n",
    "\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"ParquetQueryComparison\").getOrCreate()\n",
    "\n",
    "# Read the partitioned Parquet data\n",
    "parquet_df = spark.read.parquet(\"/Users/tatianaflores/Desktop/home_sales_partitioned\")\n",
    "\n",
    "# Register the parquet DataFrame as a temp view (optional but useful for SQL)\n",
    "parquet_df.createOrReplaceTempView(\"parquet_home_sales\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "parquet_result = spark.sql(\"\"\"\n",
    "    SELECT view, ROUND(AVG(price), 2) AS average_price\n",
    "    FROM parquet_home_sales\n",
    "    GROUP BY view\n",
    "    HAVING average_price >= 350000\n",
    "    ORDER BY view DESC\n",
    "\"\"\")\n",
    "\n",
    "parquet_result.show()\n",
    "\n",
    "end_parquet = time.time()\n",
    "parquet_runtime = end_parquet - start_time\n",
    "print(f\"📦 Parquet query runtime: {parquet_runtime:.4f} seconds\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚖️  Cached vs Parquet comparison:\n",
      "    Cached runtime  : 0.3200 seconds\n",
      "    Parquet runtime : 0.3251 seconds\n",
      "    Difference      : 0.0051 seconds\n",
      "    Parquet is 1.02x slower/faster than cached\n"
     ]
    }
   ],
   "source": [
    "# Compare performance\n",
    "cached_runtime = 0.32\n",
    "\n",
    "print(f\"\\n⚖️  Cached vs Parquet comparison:\")\n",
    "print(f\"    Cached runtime  : {cached_runtime:.4f} seconds\")\n",
    "print(f\"    Parquet runtime : {parquet_runtime:.4f} seconds\")\n",
    "print(f\"    Difference      : {parquet_runtime - cached_runtime:.4f} seconds\")\n",
    "print(f\"    Parquet is {parquet_runtime / cached_runtime:.2f}x slower/faster than cached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjjYzQGjtbq8",
    "outputId": "830549fd-bb41-451b-9183-5ebf6e3e470b"
   },
   "outputs": [],
   "source": [
    "# 14. Uncache the home_sales temporary table.\n",
    "\n",
    "spark.catalog.uncacheTable(\"home_sales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sy9NBvO7tlmm",
    "outputId": "be73e0e3-5e85-4794-aad9-025fb6fa84a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 15. Check if the home_sales is no longer cached\n",
    "print(spark.catalog.isCached(\"home_sales\"))  # Should return False after uncache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Home_Sales_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
